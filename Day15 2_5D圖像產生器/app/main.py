# app/main.py  â€”â€” minimal change ç‰ˆï¼ˆä¿ç•™æ—¢æœ‰ API / äº‹ä»¶ / I/Oï¼‰
import os, io, json, base64, asyncio, logging, sys
from typing import Dict
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from sse_starlette.sse import EventSourceResponse
from PIL import Image
import numpy as np
import cv2
from dotenv import load_dotenv

from .processors.utils import ensure_dirs, SSEQueue, unique_id, resize_to_supported_size
from .processors.depth_anything_ort import compute_depth_map
from .processors.yolo11_seg import load_yolo11_seg, person_instances, union_mask
from .processors.gpt_image import stream_repaint_single_image_responses
from .processors.compose_25d import (
    normalize_depth,          # æ·±åº¦ 0..1 æ­£è¦åŒ–
    build_instances_payload,  # ä¾é®ç½©ç”¢ RGBAï¼ˆåªå¤–æ¨é€æ˜åº¦ï¼‰ä¸¦å­˜æª”
    build_final_payload,      # çµ„ final payload ä¸¦å­˜ bg/depth
    save_intermediates        # å¯é¸ï¼šæŠŠå››æ ¼éç¨‹åœ–ä¹Ÿè½åœ°
)
load_dotenv()

LOG_DIR = os.path.join(os.path.dirname(__file__), "../logs"); os.makedirs(LOG_DIR, exist_ok=True)
logging.basicConfig(level=logging.DEBUG, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[logging.StreamHandler(sys.stdout), logging.FileHandler(os.path.join(LOG_DIR, "server.log"), encoding="utf-8")])
logger = logging.getLogger("2p5d")

ROOT = os.path.dirname(os.path.abspath(__file__))
STATIC = os.path.join(ROOT, "static")
UPLOAD_DIR = os.path.join(ROOT, "../data/uploads")
ensure_dirs(UPLOAD_DIR)
OUTPUT_DIR = os.path.join(ROOT, "../data/outputs")
ensure_dirs(OUTPUT_DIR)

DEPTH_ONNX = os.getenv("DEPTH_ANYTHING_ONNX", "./models/DepthAnything/depth_anything_vitl.onnx")
YOLO_ONNX = os.getenv("YOLO11M_SEG_ONNX", "./models/YOLOv11/yolo11m-seg.onnx")
DEVICE = os.getenv("ULTRALYTICS_DEVICE", "cpu")

app = FastAPI(title="2.5D Studio v17", version="1.7")
app.mount("/static", StaticFiles(directory=STATIC), name="static")


def to_png_bytes(img: Image.Image) -> bytes:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return buf.getvalue()

def _np_to_b64_png(np_img: np.ndarray) -> str:
    """å°‡ numpy å½±åƒï¼ˆL/RGB/RGBAï¼‰è¼¸å‡ºæˆ base64(PNG)"""
    import imageio.v2 as imageio
    buf = io.BytesIO(); imageio.imwrite(buf, np_img, format="png")
    return base64.b64encode(buf.getvalue()).decode("utf-8")


# >>> CHG: å°å·¥å…· â€”â€” è®€å› base64(PNG) æˆ RGBAï¼›ä»¥åŠä»¥æ–°èƒŒæ™¯åƒç´ é‡æŸ“å¤–åœˆåŠé€æ˜å€
def _b64_png_to_np_rgba(b64_str: str) -> np.ndarray:
    import imageio.v2 as imageio
    data = base64.b64decode(b64_str)
    arr = imageio.imread(io.BytesIO(data))
    # å¼·åˆ¶ RGBAï¼ˆæœ‰äº›ç·¨ç¢¼å™¨å¯èƒ½å›å‚³ RGBï¼‰
    if arr.ndim == 3 and arr.shape[2] == 3:
        rgba = np.zeros((arr.shape[0], arr.shape[1], 4), dtype=np.uint8)
        rgba[..., :3] = arr
        rgba[..., 3] = 255
        return rgba
    return arr

def _recolor_outer_fringes(instances_payload, insts, bg_img_rgb: np.ndarray):
    """
    ç›®æ¨™ï¼šæŠŠã€Œé®ç½©å¤–ï¼ˆmask==0ï¼‰ä½† alpha>0ã€çš„åƒç´  RGB æ”¹ç‚ºæ–°èƒŒæ™¯é¡è‰²ï¼Œ
    æ¶ˆé™¤ç™½é‚Šã€‚å°±åœ°æ›´æ–° instances_payload[*]['img_b64']ï¼Œä¸æ”¹ schemaã€‚
    """
    # æº–å‚™ id -> mask æ˜ å°„ï¼ˆuint8 0/255ï¼‰
    id2mask = {}
    for i, inst in enumerate(insts):
        mu = inst.get("mask")
        if mu is None:
            continue
        mu_u8 = (mu > 0).astype(np.uint8) * 255 if mu.dtype != np.uint8 else mu
        id2mask[int(inst.get("id", i))] = mu_u8

    H, W = bg_img_rgb.shape[:2]

    for idx, item in enumerate(instances_payload):
        try:
            inst_id = int(item.get("id", idx))
            mask = id2mask.get(inst_id, None)
            if mask is None:
                # é€€è€Œæ±‚å…¶æ¬¡ï¼šä»¥åºè™Ÿå°é½Š
                keys = list(id2mask.keys())
                if idx < len(keys): mask = id2mask[keys[idx]]
            if mask is None:
                continue

            rgba = _b64_png_to_np_rgba(item["img_b64"])
            # å°ºå¯¸å°é½Šï¼ˆç†è«–ä¸Šèˆ‡ç•«å¸ƒä¸€è‡´ï¼›ç©©å¥èµ·è¦‹ still checkï¼‰
            h, w = rgba.shape[:2]
            if (h, w) != (H, W):
                # ä»¥èƒŒæ™¯ç‚ºåŸºæº–ï¼Œresize RGBA èˆ‡ mask
                rgba = cv2.resize(rgba, (W, H), interpolation=cv2.INTER_LINEAR)
                mask = cv2.resize(mask, (W, H), interpolation=cv2.INTER_NEAREST)
                h, w = H, W
            elif mask.shape != (h, w):
                mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)

            alpha = rgba[..., 3]
            ext = (mask == 0) & (alpha > 0)

            if np.any(ext):
                rgba[ext, :3] = bg_img_rgb[ext, :3]  # ç”¨æ–°èƒŒæ™¯åƒç´ è¦†å¯«
                # å›å¯«æˆ base64
                item["img_b64"] = _np_to_b64_png(rgba)
        except Exception as e:
            logger.warning(f"recolor outer fringe failed on instance[{idx}]: {e}")

@app.get("/", response_class=HTMLResponse)
def home():
    with open(os.path.join(STATIC, "index.html"), "r", encoding="utf-8") as f:
        return HTMLResponse(f.read())

@app.post("/api/upload")
async def upload(file: UploadFile = File(...)):
    content = await file.read()
    fid = unique_id("file")
    dst = os.path.join(UPLOAD_DIR, f"{fid}.png")
    Image.open(io.BytesIO(content)).convert("RGBA").save(dst)
    return {"file_id": fid, "path": dst}

TASKS: Dict[str, SSEQueue] = {}

@app.post("/api/run")
async def run(file_id: str, partial_images: int = 3):
    upath = os.path.join(UPLOAD_DIR, f"{file_id}.png")
    if not os.path.isfile(upath): raise HTTPException(404, "file not found")
    task_id = unique_id("task")
    q = SSEQueue(); TASKS[task_id] = q
    asyncio.create_task(pipeline(task_id, q, upath, partial_images))
    return {"task_id": task_id}

@app.get("/api/stream/{task_id}")
async def stream(task_id: str):
    if task_id not in TASKS: raise HTTPException(404, "task not found")
    q = TASKS[task_id]
    async def event_gen():
        async for item in q.consume():
            yield {"event": item["event"], "data": json.dumps(item["data"])}
    return EventSourceResponse(event_gen())

async def _stream_repaint_bg(q: SSEQueue, bg_input: Image.Image, size_str: str, partial_images: int):
    """
    å‘¼å« Responses å–®åœ–é‡ç•« APIï¼Œä¸¦æŠŠ partial ç›´æ¥ä¸Ÿåˆ° SSEã€‚
    å›å‚³ï¼šæœ€çµ‚èƒŒæ™¯çš„ base64(PNG)
    """
    loop = asyncio.get_running_loop(); holder = {"b64": None}
    def worker():
        try:
            for ev in stream_repaint_single_image_responses(
                bg_image=bg_input,
                prompt="é€™æ˜¯ä¸€å¼µå·²å»é™¤å‰æ™¯äººç‰©å¾Œçš„èƒŒæ™¯åœ–ã€‚è«‹æ ¹æ“šæ®˜é¤˜åƒç´ ä¾†é€²è¡ŒåŸå ´æ™¯å…§å®¹æ¨æ–·ï¼Œç›´æ¥åŸºæ–¼æ­¤åƒç´ ã€æ•´å¼µé‡ç•«ã€ï¼Œåœ–ä¸­æ‡‰è©²çœ‹ä¸å‡ºæœ‰å‰æ™¯äººç‰©å­˜åœ¨çš„ç—•è·¡ï¼šè«‹ä¿ç•™åŸæœ‰å…‰å½±/æè³ª/é€è¦–ä¸€è‡´ï¼›è¼¸å‡ºå°ºå¯¸èˆ‡è¼¸å…¥ä¸€è‡´ã€‚",
                size=size_str,
                partial_images=partial_images
            ):
                if ev["type"]=="partial":
                    asyncio.run_coroutine_threadsafe(q.push("bg.partial", {"b64": ev["b64"]}), loop)
                elif ev["type"]=="final":
                    holder["b64"] = ev["b64"]
        except Exception as e:
            asyncio.run_coroutine_threadsafe(q.push("progress", {"message": f"âŒ èƒŒæ™¯ä¸²æµéŒ¯èª¤ï¼š{e}"}), loop)
    await asyncio.to_thread(worker)
    return holder["b64"]

async def pipeline(task_id: str, q: SSEQueue, image_path: str, partial_images: int):
    # è®€æª” & è¦æ ¼åŒ–
    await q.push("progress", {"message": "ğŸ”§ è®€å–èˆ‡è¦æ ¼åŒ–å°ºå¯¸ä¸­..."})
    image_orig = Image.open(image_path).convert("RGBA")
    image, target = resize_to_supported_size(image_orig, prefer='auto')
    size_str = f"{target[0]}x{target[1]}"
    await q.push("progress", {"message": f"âœ… è¦æ ¼åŒ–å°ºå¯¸ {size_str}ï¼ˆå°é½Š gpt-image-1ï¼‰"})

    # è½‰ numpy
    img_rgb = np.array(image.convert("RGB"))      # HxWx3 uint8
    bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

    # æ·±åº¦
    if not os.path.isfile(DEPTH_ONNX):
        await q.push("progress", {"message": "âŒ æ‰¾ä¸åˆ° DepthAnything ONNXï¼šmodels/DepthAnything/"}); return
    d = compute_depth_map(bgr, DEPTH_ONNX)        # HxW float
    d = normalize_depth(d)                         # 0..1
    depth_u8 = (np.clip(d,0,1)*255).astype(np.uint8)
    await q.push("depth", {"b64": _np_to_b64_png(depth_u8)})
    await q.push("progress", {"message": "âœ… æ·±åº¦åœ–å®Œæˆ"})

    # äººç‰©å¯¦ä¾‹åˆ†å‰²
    if not os.path.isfile(YOLO_ONNX):
        await q.push("progress", {"message": "âŒ æ‰¾ä¸åˆ° YOLO11 m-seg ONNXï¼šmodels/YOLOv11/"}); return
    yolo = load_yolo11_seg(YOLO_ONNX, device=os.getenv("ULTRALYTICS_DEVICE","cpu"))
    insts = person_instances(yolo, bgr)
    h, w = bgr.shape[:2]
    if not insts:
        await q.push("progress", {"message": "âš ï¸ æ²’åµæ¸¬åˆ°äººç‰©ï¼›ç›´æ¥è¼¸å‡ºè¦æ ¼åŒ–åŸåœ–ä½œç‚ºèƒŒæ™¯"})
        bg_b64 = _np_to_b64_png(np.array(image.convert("RGBA")))
        await q.push("final", {"bg_b64": bg_b64, "instances": [], "depth_b64": _np_to_b64_png(depth_u8)})
        return

    # union é®ç½©ï¼ˆ0/255ï¼‰â†’ å…ˆé€æ¸…æ¥šçš„ L é è¦½ï¼Œé¿å…ã€Œå·¦ä¸‹å…ˆæ˜¯å…¨é»‘ã€çš„éŒ¯è¦º
    union = union_mask(insts, (h, w))             # é æœŸç‚º uint8(0/255)
    if union.dtype != np.uint8:
        union = (union > 0).astype(np.uint8) * 255
    await q.push("mask", {"b64": _np_to_b64_png(union)})
    await q.push("progress", {"message": "ğŸ§© èƒŒæ™¯é‡ç•«ï¼ˆResponses å–®åœ–ï¼Œæ­£ç¢º payloadï¼‰..."})

    # å»äººå¾ŒèƒŒæ™¯ï¼šäººç‰©å€ alpha=0ï¼ˆä»¥ union 0/255 åç›¸ï¼‰
    arr_rgba = np.dstack([img_rgb, (255 - union).astype(np.uint8)])  # HxWx4
    bg_input = Image.fromarray(arr_rgba, "RGBA")

    # èƒŒæ™¯è£œæ´ï¼ˆä¸²æµ partialï¼‰
    bg_b64 = await _stream_repaint_bg(q, bg_input, size_str=size_str, partial_images=partial_images)
    if not bg_b64:
        await q.push("progress", {"message": "âŒ èƒŒæ™¯è£œæ´å¤±æ•—ï¼ˆResponses å–®åœ–é‡ç•«ï¼‰"}); return
    await q.push("progress", {"message": "âœ… èƒŒæ™¯é‡ç•«å®Œæˆï¼›çµ„è£å¤šå¯¦ä¾‹ 2.5D"})

    # --- å¯«ã€Œéç¨‹æª¢è¦–ã€åˆ° data/outputs/<task_id>ï¼ˆå¯é¸ï¼‰---
    # FIX: save_intermediates åªæ”¶ 4 å€‹åƒæ•¸ï¼Œä¸”ç¬¬ä¸€å€‹æ‡‰æ˜¯ PIL Imageï¼ˆä¸æ˜¯ numpyï¼‰
    save_intermediates(task_id, image.convert("RGB"), d, union)  # <-- é€™è¡Œæ˜¯æœ¬æ¬¡å”¯ä¸€å¿…è¦ä¿®æ”¹

    # --- ç”¢ç”Ÿæ‰€æœ‰å‰æ™¯ï¼ˆåªå¤–æ¨é€æ˜åº¦ï¼›ä¸å¤–æ¨é¡è‰²ï¼‰ï¼‹ å¯«å…¥ data/outputs/<task_id> ---
    instances_payload = build_instances_payload(
        task_id, img_rgb, d, insts,
        ring_px=0,        # åŠé€æ˜å¤–åœˆå¯¬åº¦ï¼ˆpxï¼‰
        ring_alpha=0.45,  # å¤–åœˆé€æ˜åº¦ï¼ˆ0~1ï¼‰
        feather_px=3,     # å†å°å¹…ç¾½åŒ–
        premultiply=False # å¦‚é‡å€‹æ¡ˆäº®é‚Šï¼Œå†æ”¹ True
    )

    # --- èƒŒæ™¯ b64 â†’ PIL ---
    bg_img = Image.open(io.BytesIO(base64.b64decode(bg_b64))).convert("RGB")

    # --- çµ„ finalï¼ˆä¹ŸæœƒæŠŠ bg.png / depth.png è½åœ°ï¼‰---
    final_payload = build_final_payload(task_id, bg_img, d, instances_payload)

    # é€æœ€çµ‚çµæœ
    await q.push("final", final_payload)
